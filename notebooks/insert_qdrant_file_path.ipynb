{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"/home/azureuser/Ambarish/llama-index/PWD/\"\n",
    "\n",
    "# Model Settings\n",
    "MODEL_NAME=\"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Qdrant server URL\n",
    "URL =\"localhost\"\n",
    "# Qdrant dimension of the collection\n",
    "DIMENSION = 384\n",
    "# Qdrant collection name\n",
    "COLLECTION_NAME = \"PWD_SENTENCE_TRANSFORMERS\"\n",
    "METRIC_NAME =\"COSINE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/Ambarish/search_engine/.venv.search.engine/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import qdrant_client as qc\n",
    "import qdrant_client.http.models as qmodels\n",
    "from qdrant_client.http.models import *\n",
    "\n",
    "import os\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_data(file_path, num_pages = 1):\n",
    "    reader = PdfReader(file_path)\n",
    "    full_doc_text = \"\"\n",
    "    pages = reader.pages\n",
    "    num_pages = len(pages) \n",
    "    \n",
    "    try:\n",
    "        for page in range(num_pages):\n",
    "            current_page = reader.pages[page]\n",
    "            text = current_page.extract_text()\n",
    "            full_doc_text += text\n",
    "    except:\n",
    "        print(\"Error reading file\")\n",
    "    finally:\n",
    "        return full_doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(fulltext:str,chunk_length =500) -> list:\n",
    "    text = fulltext\n",
    "\n",
    "    chunks = []\n",
    "    while len(text) > chunk_length:\n",
    "        last_period_index = text[:chunk_length].rfind('.')\n",
    "        if last_period_index == -1:\n",
    "            last_period_index = chunk_length\n",
    "        chunks.append(text[:last_period_index])\n",
    "        text = text[last_period_index+1:]\n",
    "    chunks.append(text)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qc.QdrantClient(url=URL)\n",
    "METRIC = qmodels.Distance.COSINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/azureuser/Ambarish/llama-index/PWD/HIGHWAYS.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full doc text length: 19932\n",
      "Full embeddings length: 48\n",
      "Inserting chunk 0 to 47\n",
      "Processing file: /home/azureuser/Ambarish/llama-index/PWD/ROAD-SAFETY.pdf\n",
      "Full doc text length: 132127\n",
      "Full embeddings length: 331\n",
      "Inserting chunk 0 to 99\n",
      "Inserting chunk 100 to 199\n",
      "Inserting chunk 200 to 299\n",
      "Inserting chunk 300 to 330\n"
     ]
    }
   ],
   "source": [
    "FILES = os.listdir(FILE_PATH)\n",
    "FILES_FULL_PATH = [FILE_PATH + file for file in FILES]\n",
    "for filename in FILES_FULL_PATH:\n",
    "    print(f'Processing file: {filename}')\n",
    "    full_doc_text = get_pdf_data(filename)\n",
    "    print(f'Full doc text length: {len(full_doc_text)}')\n",
    "    payloads = []\n",
    "    li_id = []\n",
    "    corpus = []\n",
    "    Lines =get_chunks(full_doc_text,500)\n",
    "    for token in Lines:\n",
    "        corpus.append(token)\n",
    "        payloads.append({\"token\":token,\n",
    "                         \"filename\": os.path.basename(filename),\n",
    "                           \"type\":\"pdf\"})\n",
    "        li_id.append(str(uuid.uuid4()))\n",
    "    embeddings_all = model.encode(corpus, convert_to_tensor=True)\n",
    "    print(f'Full embeddings length: {len(embeddings_all)}')\n",
    "\n",
    "    CHUNK_SIZE = 100\n",
    "    for i in range(0, len(embeddings_all), CHUNK_SIZE):\n",
    "        if(i+CHUNK_SIZE > len(embeddings_all) -1):\n",
    "            new_chunk = len(embeddings_all) -1\n",
    "        else:\n",
    "            new_chunk = i+CHUNK_SIZE -1\n",
    "        print(\"Inserting chunk\", i , \"to\", new_chunk)\n",
    "        client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            points=qmodels.Batch(\n",
    "                ids = li_id[i:new_chunk],\n",
    "                vectors=embeddings_all[i:new_chunk].tolist(),\n",
    "                payloads=payloads[i:new_chunk]\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
